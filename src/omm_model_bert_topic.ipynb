{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "###### Ordering Manufacture Materials using BERT: 17/03/23, @Soumya D.######\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5db895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing used packags\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random as rn\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from functools import partial\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.stem import SnowballStemmer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#To remove warninigs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a58b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loadinig the data\n",
    "\n",
    "data_raw = pd.read_excel(r'../data/data_sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of dataframe\n",
    "print(data_raw.shape)\n",
    "# display the head of data\n",
    "display(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#details datafarme information\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying a working df\n",
    "\n",
    "data = data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Name'] = data['Name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394a774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = ' '.join(txt for txt in data.Name )\n",
    "plt.figure(figsize=(15, 8))\n",
    "wordcloud = WordCloud(\n",
    "    background_color='black',\n",
    "    max_font_size=100,\n",
    "    max_words=100, \n",
    "    width=1000, \n",
    "    height=700\n",
    ").generate(txt)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b05eda",
   "metadata": {},
   "source": [
    "### Basic Text Cleaninig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511857e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clan punctuation\n",
    "\n",
    "def clean_punctuation(text):\n",
    "    result = \"\".join(u for u in text if u not in (\"?\", \".\", \";\", \":\",  \"!\",'\"',',') )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean unify whitespaces\n",
    "\n",
    "def clean_unify_whitespaces(text):\n",
    "    cleaned_string = re.sub(' +', ' ', text )\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Numeric\n",
    "\n",
    "def clean_num(texts):\n",
    "    output = re.sub(r'\\d+', '', texts )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic characters cleaninig \n",
    "\n",
    "def basic_clean(txt):\n",
    "    \"\"\" Remove hyperlinks and markup \"\"\"\n",
    "    result = re.sub(\"<[a][^>]*>(.+?)</[a]>\", 'Link.', txt)\n",
    "    result = re.sub('&gt;', \"\", result)\n",
    "    result = re.sub('&#x27;', \"'\", result)\n",
    "    result = re.sub('&quot;', '\"', result)\n",
    "    result = re.sub('&#x2F;', ' ', result)\n",
    "    result = re.sub('<p>', ' ', result)\n",
    "    result = re.sub('</i>', '', result)\n",
    "    result = re.sub('&#62;', '', result)\n",
    "    result = re.sub('<i>', ' ', result)\n",
    "    result = re.sub(\"\\n\", '', result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop word cleaning \n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop ]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91483740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to use stemming to normalize words\n",
    "\n",
    "def Stemming(text):\n",
    "    stem = []\n",
    "    stopword = stopwords.words('english')\n",
    "    snowball_stemmer = SnowballStemmer('english')\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    stemmed_word = [ snowball_stemmer.stem(word) for word in word_tokens ]\n",
    "    stem = ' '.join(stemmed_word)\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb77d7",
   "metadata": {},
   "source": [
    "#### Applying all these above methods to data[ 'Name' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af55fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data, Name):\n",
    "    data_cleaned  = data.copy()\n",
    "    data_cleaned[Name] = data_cleaned['Name']\n",
    "    data_cleaned[Name] = data_cleaned[Name].apply(clean_punctuation)\n",
    "    data_cleaned[Name] = data_cleaned[Name].apply(clean_unify_whitespaces)\n",
    "    data_cleaned[Name] = data_cleaned[Name].apply(clean_num)\n",
    "    data_cleaned[Name] = data_cleaned[Name].apply(basic_clean)\n",
    "    data_cleaned[Name] = data_cleaned[Name].apply(clean_stopwords)\n",
    "    data_cleaned[Name] = data_cleaned[Name].apply(Stemming)\n",
    "    return data_cleaned\n",
    "\n",
    "data_cleaned = cleaning(data, 'clean_name' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52230db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e564509",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_cleaned[['Name','clean_name','AT_MaraMatkl','AT_MaraMaktx','AT_MaraBrgew','AT_MaraMtart','AT_MaraLabor','AT_MaraBrgew_UnitID']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09e49b",
   "metadata": {},
   "source": [
    "\n",
    "#### BERT Topics and Document embedings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead5928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c47d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Topics\n",
    "\n",
    "model = BERTopic(language=\"english\")\n",
    "topics, probs = model.fit_transform(df['clean_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84467ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic(0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.backend import languages\n",
    "print(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Embedding model\n",
    "\n",
    "#st_model = BERTopic(embedding_model=\"xlm-r-bert-base-nli-stsb-mean-tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Topics\n",
    "model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e3ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic Reduction\n",
    "model.reduce_topics(docs, nr_topics=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe655aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic Representation\n",
    "\n",
    "model.update_topics(docs, n_gram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search Topics\n",
    "similar_topics, similarity = model.find_topics(\"gpu\", top_n=5); similar_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model serialization\n",
    "# Save model\n",
    "model.save(\"my_model\")\n",
    "\n",
    "# Load model\n",
    "my_model = BERTopic.load(\"my_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
